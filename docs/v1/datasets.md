# Datasets

## TheoremIndex Format

All theorem files use the TheoremIndex JSON format:

```json
{
  "theorems": [
    {"name": "Nat.add_comm", "statement": "‚àÄ (n m : Nat), n + m = m + n"}
  ]
}
```

Optional fields: `file_path`, `line_number` (present in Mathlib-traced data).

Statements are `‚àÄ`-expressions suitable for Pantograph's `goal.start(expr)`. For pre-compiled theorems, Pantograph uses `copyFrom(name)` instead.

## miniF2F Benchmarks

488 competition math problems (AMC, AIME, IMO) + high-school/undergraduate math. Split into 244 test + 244 validation.

### Versions

| Version | Source | Description |
|---------|--------|-------------|
| **v1** | [yangky11/miniF2F-lean4](https://github.com/yangky11/miniF2F-lean4) | Original Lean 4 port. Some known statement bugs. |
| **v2s** (simplified) | [roozbeh-yz/miniF2F_v2](https://github.com/roozbeh-yz/miniF2F_v2) | Corrected statements matching informal problems. Direct answers (e.g., `IsLeast S 49`). |
| **v2c** (competition) | Same repo | Original competition wording. Multiple-choice where applicable (e.g., `a = 49 ‚à® a = 50 ‚à® ...`). Easier to prove than v2s. |

Reference: [miniF2F-Lean Revisited](https://arxiv.org/abs/2511.03108) (NeurIPS 2025).

### Files

| File | Theorems | Description |
|------|----------|-------------|
| `minif2f_test.json` | 244 | v1 test split |
| `minif2f_valid.json` | 244 | v1 validation split |
| `minif2f_v2s_test.json` | 244 | v2s test split |
| `minif2f_v2s_valid.json` | 244 | v2s validation split |
| `minif2f_v2c_test.json` | 244 | v2c test split |
| `minif2f_v2c_valid.json` | 244 | v2c validation split |

### Olean Compilation

Theorems are pre-compiled into `.olean` files so Pantograph can use fast `copyFrom(name)` lookup instead of slow expression elaboration (60s+ for complex types).

```bash
# Generate all 6 benchmark files:
for pair in \
  "minif2f_test.json BenchMinIF2FTest" \
  "minif2f_valid.json BenchMinIF2FValid" \
  "minif2f_v2s_test.json BenchMinIF2FV2STest" \
  "minif2f_v2s_valid.json BenchMinIF2FV2SValid" \
  "minif2f_v2c_test.json BenchMinIF2FV2CTest" \
  "minif2f_v2c_valid.json BenchMinIF2FV2CValid"; do
  set -- $pair
  python python/data/generate_benchmark_lean.py \
    --input "data/$1" --output "vendor/Pantograph/$2.lean" --module-name "$2"
done

cd vendor/Pantograph && lake build \
  BenchMinIF2FTest BenchMinIF2FValid \
  BenchMinIF2FV2STest BenchMinIF2FV2SValid \
  BenchMinIF2FV2CTest BenchMinIF2FV2CValid
```

The generator applies syntax fixes for Mathlib v4.27.0 compatibility:
- `‚àë k in S` ‚Üí `‚àë k ‚àà S` (deprecated BigOperators notation)
- `{x | P}` ‚Üí `({x | P})` (set-builder parser disambiguation)
- `{x, ‚Ñù | P}` ‚Üí `{x : ‚Ñù | P}` (malformed set-builder type annotation in v2c)
- `(n + 2)!` ‚Üí `(Nat.factorial (n + 2))` (factorial notation)
- `= ![7, -1]` ‚Üí `= (EuclideanSpace.equiv _ ‚Ñù).symm ![7, -1]` (coercion fix)
- `ùìù` ‚Üí `nhds` (requires `open Topology`)
- `-- comment` stripping (v1 inline comments)
- `^ (1/3)` ‚Üí `^ ((1 : ‚Ñù)/3)` (integer division in exponents)
- `‚àÉ x, ‚Ñ§,` ‚Üí `‚àÉ x : ‚Ñ§,` (malformed binder in v2s)
- `‚àÄ IsGreatest` ‚Üí `IsGreatest` (missing binder variable in v2s)
- `let c, =` ‚Üí `let c :=` (v2s typo)
- v2c compound `abbrev` + `theorem` declarations split and emitted correctly
- v2c `,` conclusion separator ‚Üí `:` in theorem declarations

All 1,464 theorems (6 datasets √ó 244) compile with zero errors.

## Mathlib Corpus

| File | Theorems | Description |
|------|----------|-------------|
| `theorem_index.json` | 61,233 | Full Mathlib4 theorem corpus from LeanDojo trace. Primary source for expert iteration search. |

## IMO-Steps

| File | Theorems | Description |
|------|----------|-------------|
| `imo_steps_theorems.json` | 21 | Full IMO problem statements (imo_1959_p1, etc.) |
| `imo_steps_lemmas.json` | 1,328 | Individual proof step lemmas from IMO proofs |

## Special-Purpose Sets

| File | Theorems | Description |
|------|----------|-------------|
| `train_eval_theorems.json` | 198 | Quick model validation during training |
| `ebm_trivial_theorems.json` | 1,672 | "Easy" theorems (provable in ‚â§1 step) |
| `smoke_theorems.json` | 6 | Minimal smoke test |
| `test_theorems.json` | 16 | Integration test set |
| `test_quick.json` | 3 | CI quick check |

## Tactic Pairs

Training data for LLM fine-tuning, extracted from Mathlib proof traces.

| File | Rows | Format |
|------|------|--------|
| `tactic_pairs/train.jsonl` | 246,601 | `{"state": "...", "tactic": "..."}` |
| `tactic_pairs/val.jsonl` | 12,979 | Same |
| `tactic_pairs/train_formatted.jsonl` | 246,526 | `[GOAL]{state}[PROOFSTEP]{tactic}<eos>` |
| `tactic_pairs/val_formatted.jsonl` | 12,970 | Same |

Formatted files match the prompt format in `crates/policy/src/model.rs`. Generated by `python/data/prepare_tactic_pairs.py` with max 2048 token length filter.

## Trajectory Parquet Files

Proof search results stored as parquet. Schema (from `crates/trajectory/src/types.rs`):

| Column | Type | Description |
|--------|------|-------------|
| `theorem_name` | String | Theorem being proved |
| `state_id` | u64 | Pantograph state ID |
| `state_pp` | String | Pretty-printed proof state |
| `tactic_applied` | String | Tactic used (empty for root) |
| `parent_state_id` | Option<u64> | Parent state |
| `label` | String | `positive` / `negative` / `unknown` |
| `depth_from_root` | u32 | Steps from initial goal |
| `remaining_depth` | i32 | Steps to proof (-1 if unknown) |
| `llm_log_prob` | f64 | Policy log probability |
| `ebm_score` | f64 | Energy score (0.0 if not used) |
| `is_proof_complete` | bool | Whether proof was found |
| `timestamp_ms` | u64 | Timestamp |

### Expert Iteration Trajectories

| File | Records | Description |
|------|---------|-------------|
| `iter_0.parquet` | ~3,800 | Baseline search (no fine-tuning) |
| `iter_1.parquet` | ~140,000 | After first LLM fine-tune |
| `iter_2.parquet` | ~250,000 | After second LLM fine-tune |

## Data Pipeline

```
prepare_data.sh
‚îú‚îÄ‚îÄ download_minif2f.py      ‚Üí minif2f_{test,valid}.json
‚îú‚îÄ‚îÄ prepare_tactic_pairs.py  ‚Üí tactic_pairs/*_formatted.jsonl
‚îî‚îÄ‚îÄ generate_benchmark_lean.py ‚Üí vendor/Pantograph/Bench*.lean ‚Üí lake build

Expert iteration loop (scripts/run_iteration_*.sh):
  search (theorems.json ‚Üí trajectories.parquet)
  ‚Üí train-ebm (trajectories.parquet ‚Üí checkpoints/ebm/iter_N)
  ‚Üí finetune LLM (tactic_pairs ‚Üí models/llm/iter_N)
  ‚Üí repeat
```
